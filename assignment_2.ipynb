{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, if a question can be answered with 'yes/no', or a numeric value, you may simply state as much. If you incorporate code from the internet (which is not required and generally not advisable), please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "We will go through comparable code and concepts in the live learning sessions. If you run into trouble, start by using the help `help()` function in Python, to get information about the datasets and function in question. The internet is also a great resource when coding (though note that no outside searches are required by the assignment!). If you do incorporate code from the internet, please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "Please bring questions that you cannot work out on your own to office hours, work periods or share with your peers on Slack. We will work with you through the issue.\n",
    "\n",
    "If you like, you may collaborate with others in the cohort. If you choose to do so, please indicate with whom you have worked with in your pull request by tagging their GitHub username. Separate submissions are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Import specific objects\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from ISLP import load_data\n",
    "from ISLP import confusion_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Classification using KNN\n",
    "\n",
    "We'll now use the `Caravan` dataset from the `ISLP` package. (You may use `Caravan.describe()` to review details of the dataset.) In this dataset, the response variable of interest is `Purchase`, which indicates if a given customer purchased a caravan insurance policy. We will simultaneously use all other variables in the dataset to predict the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n",
      "    MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  MGODOV  \\\n",
      "0        33         1        3         2         8       0       5       1   \n",
      "1        37         1        2         2         8       1       4       1   \n",
      "2        37         1        2         2         8       0       4       2   \n",
      "3         9         1        3         3         3       2       3       2   \n",
      "4        40         1        4         2        10       1       4       1   \n",
      "5        23         1        2         1         5       0       5       0   \n",
      "6        39         2        3         2         9       2       2       0   \n",
      "7        33         1        2         3         8       0       7       0   \n",
      "8        33         1        2         4         8       0       1       3   \n",
      "9        11         2        3         3         3       3       5       0   \n",
      "10       10         1        4         3         3       1       4       1   \n",
      "11        9         1        3         3         3       1       3       2   \n",
      "12       33         1        2         3         8       1       4       1   \n",
      "13       41         1        3         3        10       0       5       0   \n",
      "14       23         1        1         2         5       0       6       1   \n",
      "15       33         1        2         3         8       0       7       0   \n",
      "16       38         1        2         3         9       0       6       0   \n",
      "17       22         2        3         3         5       0       5       0   \n",
      "18       13         1        4         2         3       2       4       0   \n",
      "19       31         1        2         4         7       0       2       0   \n",
      "20       33         1        4         3         8       0       6       0   \n",
      "21       33         2        3         3         8       0       4       2   \n",
      "22       13         1        3         2         3       1       7       0   \n",
      "23       34         2        3         2         8       0       7       0   \n",
      "24       13         2        4         3         3       0       4       2   \n",
      "25       33         1        3         3         8       0       6       1   \n",
      "26       37         1        3         3         8       0       5       0   \n",
      "27       40         1        3         3        10       0       3       0   \n",
      "28       31         1        4         2         7       0       9       0   \n",
      "29       33         2        2         3         8       0       7       1   \n",
      "30       24         2        2         2         5       1       3       2   \n",
      "31       23         1        2         2         5       2       4       2   \n",
      "32       33         1        4         3         8       1       4       1   \n",
      "33       38         1        2         3         9       0       5       2   \n",
      "34       13         2        4         3         3       0       4       2   \n",
      "35        8         1        3         2         2       2       4       1   \n",
      "36        7         1        3         2         2       0       7       2   \n",
      "37       41         1        3         3        10       0       7       1   \n",
      "38       39         1        3         2         9       0       6       0   \n",
      "39       33         2        3         3         8       0       2       3   \n",
      "40       24         1        3         3         5       1       5       1   \n",
      "41       11         1        3         3         3       2       7       0   \n",
      "42        8         1        3         3         2       1       4       1   \n",
      "43       33         1        2         4         8       0       5       0   \n",
      "44        3         1        3         3         1       2       7       0   \n",
      "45       38         1        3         3         9       0       5       1   \n",
      "46       36         1        2         4         8       1       5       1   \n",
      "47       38         1        4         2         9       0       4       0   \n",
      "48       39         1        3         3         9       2       4       1   \n",
      "49       33         2        3         3         8       0       4       0   \n",
      "\n",
      "    MGODGE  MRELGE  ...  APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  \\\n",
      "0        3       7  ...         0        0        0       1        0   \n",
      "1        4       6  ...         0        0        0       1        0   \n",
      "2        4       3  ...         0        0        0       1        0   \n",
      "3        4       5  ...         0        0        0       1        0   \n",
      "4        4       7  ...         0        0        0       1        0   \n",
      "5        5       0  ...         0        0        0       0        0   \n",
      "6        5       7  ...         0        0        0       0        0   \n",
      "7        2       7  ...         0        0        0       0        0   \n",
      "8        6       6  ...         0        0        0       0        0   \n",
      "9        2       7  ...         0        0        0       1        0   \n",
      "10       4       7  ...         0        0        0       0        0   \n",
      "11       4       7  ...         0        0        0       1        0   \n",
      "12       4       6  ...         0        0        0       0        0   \n",
      "13       4       7  ...         0        0        0       0        0   \n",
      "14       2       1  ...         0        0        0       1        0   \n",
      "15       2       7  ...         0        0        0       1        0   \n",
      "16       3       7  ...         0        0        0       0        0   \n",
      "17       4       7  ...         0        0        0       1        0   \n",
      "18       3       7  ...         0        0        0       1        0   \n",
      "19       7       9  ...         0        0        0       0        0   \n",
      "20       3       9  ...         0        0        0       0        0   \n",
      "21       3       7  ...         0        0        0       1        0   \n",
      "22       2       7  ...         0        0        0       1        0   \n",
      "23       2       7  ...         0        0        0       0        0   \n",
      "24       4       8  ...         0        0        0       0        0   \n",
      "25       2       6  ...         0        0        0       1        0   \n",
      "26       4       7  ...         0        0        0       0        0   \n",
      "27       6       9  ...         0        0        0       1        0   \n",
      "28       0       5  ...         0        0        0       0        0   \n",
      "29       2       5  ...         0        0        0       1        0   \n",
      "30       4       2  ...         0        0        0       1        0   \n",
      "31       4       7  ...         0        0        0       0        0   \n",
      "32       5       8  ...         0        0        0       1        0   \n",
      "33       2       4  ...         0        0        0       0        0   \n",
      "34       4       8  ...         0        0        0       1        0   \n",
      "35       4       6  ...         0        1        0       1        0   \n",
      "36       0       7  ...         0        0        0       1        0   \n",
      "37       2       8  ...         0        0        0       1        0   \n",
      "38       3       6  ...         0        0        0       1        0   \n",
      "39       5       6  ...         0        0        0       1        0   \n",
      "40       3       6  ...         0        0        0       1        0   \n",
      "41       0       9  ...         0        0        0       2        0   \n",
      "42       4       6  ...         0        0        0       1        0   \n",
      "43       4       8  ...         0        0        0       0        0   \n",
      "44       0       7  ...         0        0        0       1        0   \n",
      "45       3       7  ...         0        0        0       1        0   \n",
      "46       3       6  ...         0        0        0       1        0   \n",
      "47       5       8  ...         0        0        0       1        0   \n",
      "48       3       8  ...         0        0        0       0        0   \n",
      "49       5       7  ...         0        0        0       1        0   \n",
      "\n",
      "    APLEZIER  AFIETS  AINBOED  ABYSTAND  Purchase  \n",
      "0          0       0        0         0        No  \n",
      "1          0       0        0         0        No  \n",
      "2          0       0        0         0        No  \n",
      "3          0       0        0         0        No  \n",
      "4          0       0        0         0        No  \n",
      "5          0       0        0         0        No  \n",
      "6          0       0        0         0        No  \n",
      "7          0       0        0         0        No  \n",
      "8          0       0        0         0        No  \n",
      "9          0       0        0         0        No  \n",
      "10         0       0        0         0        No  \n",
      "11         0       0        0         0        No  \n",
      "12         0       0        0         0        No  \n",
      "13         0       0        0         0        No  \n",
      "14         0       0        0         0        No  \n",
      "15         0       0        0         0        No  \n",
      "16         0       0        0         0        No  \n",
      "17         0       0        0         0        No  \n",
      "18         0       0        0         0        No  \n",
      "19         0       0        0         0        No  \n",
      "20         0       0        0         0        No  \n",
      "21         0       0        0         0        No  \n",
      "22         0       0        0         0        No  \n",
      "23         0       0        0         0        No  \n",
      "24         0       1        0         0        No  \n",
      "25         0       0        0         0        No  \n",
      "26         0       0        0         0        No  \n",
      "27         0       0        0         0        No  \n",
      "28         0       0        0         0        No  \n",
      "29         0       0        0         0        No  \n",
      "30         0       0        0         0        No  \n",
      "31         0       0        0         0        No  \n",
      "32         0       0        0         0        No  \n",
      "33         0       0        0         0        No  \n",
      "34         0       0        0         0        No  \n",
      "35         0       0        0         1        No  \n",
      "36         0       0        0         0        No  \n",
      "37         0       0        0         0        No  \n",
      "38         0       0        0         0        No  \n",
      "39         0       0        1         0        No  \n",
      "40         0       0        0         0        No  \n",
      "41         0       1        0         0       Yes  \n",
      "42         0       0        0         0        No  \n",
      "43         0       0        0         0        No  \n",
      "44         0       0        0         0        No  \n",
      "45         0       0        0         0       Yes  \n",
      "46         0       0        0         0        No  \n",
      "47         0       0        0         0        No  \n",
      "48         0       0        0         0        No  \n",
      "49         0       0        0         0        No  \n",
      "\n",
      "[50 rows x 86 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['MOSTYPE', 'MAANTHUI', 'MGEMOMV', 'MGEMLEEF', 'MOSHOOFD', 'MGODRK',\n",
       "       'MGODPR', 'MGODOV', 'MGODGE', 'MRELGE', 'MRELSA', 'MRELOV', 'MFALLEEN',\n",
       "       'MFGEKIND', 'MFWEKIND', 'MOPLHOOG', 'MOPLMIDD', 'MOPLLAAG', 'MBERHOOG',\n",
       "       'MBERZELF', 'MBERBOER', 'MBERMIDD', 'MBERARBG', 'MBERARBO', 'MSKA',\n",
       "       'MSKB1', 'MSKB2', 'MSKC', 'MSKD', 'MHHUUR', 'MHKOOP', 'MAUT1', 'MAUT2',\n",
       "       'MAUT0', 'MZFONDS', 'MZPART', 'MINKM30', 'MINK3045', 'MINK4575',\n",
       "       'MINK7512', 'MINK123M', 'MINKGEM', 'MKOOPKLA', 'PWAPART', 'PWABEDR',\n",
       "       'PWALAND', 'PPERSAUT', 'PBESAUT', 'PMOTSCO', 'PVRAAUT', 'PAANHANG',\n",
       "       'PTRACTOR', 'PWERKT', 'PBROM', 'PLEVEN', 'PPERSONG', 'PGEZONG',\n",
       "       'PWAOREG', 'PBRAND', 'PZEILPL', 'PPLEZIER', 'PFIETS', 'PINBOED',\n",
       "       'PBYSTAND', 'AWAPART', 'AWABEDR', 'AWALAND', 'APERSAUT', 'ABESAUT',\n",
       "       'AMOTSCO', 'AVRAAUT', 'AAANHANG', 'ATRACTOR', 'AWERKT', 'ABROM',\n",
       "       'ALEVEN', 'APERSONG', 'AGEZONG', 'AWAOREG', 'ABRAND', 'AZEILPL',\n",
       "       'APLEZIER', 'AFIETS', 'AINBOED', 'ABYSTAND'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the \"Caravan\" dataset using the \"load_data\" function from the ISLP package\n",
    "Caravan = load_data('Caravan')\n",
    "\n",
    "# Add your code here\n",
    "count = (Caravan['Purchase'] == 'Yes').sum()\n",
    "print ( count )\n",
    "print ( Caravan.head(50) )\n",
    "Caravan.describe().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting any model, it is essential to understand our data. Answer the following questions about the `Caravan` dataset (Hint: use `print` and `describe`):  \n",
    "_(i)_ How many observations (rows) does the dataset contain?    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of raws is  5822\n"
     ]
    }
   ],
   "source": [
    "print( \"Number of raws is \", Caravan.shape[0] )          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(ii)_ How many variables (columns) does the dataset contain?    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns is  86\n"
     ]
    }
   ],
   "source": [
    "print( \"Number of columns is \", Caravan.shape[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(iii)_ What 'variable' type is the response variable `Purchase` (e.g., 'character', 'factor', 'numeric', etc)? What are the 'levels' of the variable?    \n",
    "\n",
    "Response `Purchase` is bolean, qualitative variable type.\n",
    "There is two levels of variable :   0 - \"No\"\n",
    "                                    1 - \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(iv)_ How many predictor variables do we have (Hint: all variables other than `Purchase`)?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictors is  85\n"
     ]
    }
   ],
   "source": [
    "# Add your code here\n",
    "print( \"Number of predictors is \", Caravan.shape[1] - 1 )             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must preform 'pre-processing' or 'data munging', to prepare our data for classification/prediction. For KNN, there are three essential steps. A first essential step is to 'standardize' the predictor variables. We can achieve this using the `scaler` method, provided as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MOSTYPE  MAANTHUI   MGEMOMV  MGEMLEEF  MOSHOOFD    MGODRK    MGODPR  \\\n",
      "0   0.680906 -0.272580  0.406697 -1.216964  0.779405 -0.694311  0.217444   \n",
      "1   0.992297 -0.272580 -0.859500 -1.216964  0.779405  0.302552 -0.365410   \n",
      "2   0.992297 -0.272580 -0.859500 -1.216964  0.779405 -0.694311 -0.365410   \n",
      "3  -1.187437 -0.272580  0.406697  0.010755 -0.970980  1.299414 -0.948264   \n",
      "4   1.225840 -0.272580  1.672893 -1.216964  1.479559  0.302552 -0.365410   \n",
      "5  -0.097570 -0.272580 -0.859500 -2.444683 -0.270826 -0.694311  0.217444   \n",
      "6   1.147992  2.191644  0.406697 -1.216964  1.129482  1.299414 -1.531118   \n",
      "7   0.680906 -0.272580 -0.859500  0.010755  0.779405 -0.694311  1.383152   \n",
      "8   0.680906 -0.272580 -0.859500  1.238473  0.779405 -0.694311 -2.113972   \n",
      "9  -1.031742  2.191644  0.406697  0.010755 -0.970980  2.296276  0.217444   \n",
      "10 -1.109590 -0.272580  1.672893  0.010755 -0.970980  0.302552 -0.365410   \n",
      "11 -1.187437 -0.272580  0.406697  0.010755 -0.970980  0.302552 -0.948264   \n",
      "12  0.680906 -0.272580 -0.859500  0.010755  0.779405  0.302552 -0.365410   \n",
      "13  1.303687 -0.272580  0.406697  0.010755  1.479559 -0.694311  0.217444   \n",
      "14 -0.097570 -0.272580 -2.125697 -1.216964 -0.270826 -0.694311  0.800298   \n",
      "15  0.680906 -0.272580 -0.859500  0.010755  0.779405 -0.694311  1.383152   \n",
      "16  1.070144 -0.272580 -0.859500  0.010755  1.129482 -0.694311  0.800298   \n",
      "17 -0.175418  2.191644  0.406697  0.010755 -0.270826 -0.694311  0.217444   \n",
      "18 -0.876047 -0.272580  1.672893 -1.216964 -0.970980  1.299414 -0.365410   \n",
      "19  0.525211 -0.272580 -0.859500  1.238473  0.429328 -0.694311 -1.531118   \n",
      "20  0.680906 -0.272580  1.672893  0.010755  0.779405 -0.694311  0.800298   \n",
      "21  0.680906  2.191644  0.406697  0.010755  0.779405 -0.694311 -0.365410   \n",
      "22 -0.876047 -0.272580  0.406697 -1.216964 -0.970980  0.302552  1.383152   \n",
      "23  0.758754  2.191644  0.406697 -1.216964  0.779405 -0.694311  1.383152   \n",
      "24 -0.876047  2.191644  1.672893  0.010755 -0.970980 -0.694311 -0.365410   \n",
      "25  0.680906 -0.272580  0.406697  0.010755  0.779405 -0.694311  0.800298   \n",
      "26  0.992297 -0.272580  0.406697  0.010755  0.779405 -0.694311  0.217444   \n",
      "27  1.225840 -0.272580  0.406697  0.010755  1.479559 -0.694311 -0.948264   \n",
      "28  0.525211 -0.272580  1.672893 -1.216964  0.429328 -0.694311  2.548861   \n",
      "29  0.680906  2.191644 -0.859500  0.010755  0.779405 -0.694311  1.383152   \n",
      "30 -0.019723  2.191644 -0.859500 -1.216964 -0.270826  0.302552 -0.948264   \n",
      "31 -0.097570 -0.272580 -0.859500 -1.216964 -0.270826  1.299414 -0.365410   \n",
      "32  0.680906 -0.272580  1.672893  0.010755  0.779405  0.302552 -0.365410   \n",
      "33  1.070144 -0.272580 -0.859500  0.010755  1.129482 -0.694311  0.217444   \n",
      "34 -0.876047  2.191644  1.672893  0.010755 -0.970980 -0.694311 -0.365410   \n",
      "35 -1.265285 -0.272580  0.406697 -1.216964 -1.321057  1.299414 -0.365410   \n",
      "36 -1.343133 -0.272580  0.406697 -1.216964 -1.321057 -0.694311  1.383152   \n",
      "37  1.303687 -0.272580  0.406697  0.010755  1.479559 -0.694311  1.383152   \n",
      "38  1.147992 -0.272580  0.406697 -1.216964  1.129482 -0.694311  0.800298   \n",
      "39  0.680906  2.191644  0.406697  0.010755  0.779405 -0.694311 -1.531118   \n",
      "40 -0.019723 -0.272580  0.406697  0.010755 -0.270826  0.302552  0.217444   \n",
      "41 -1.031742 -0.272580  0.406697  0.010755 -0.970980  1.299414  1.383152   \n",
      "42 -1.265285 -0.272580  0.406697  0.010755 -1.321057  0.302552 -0.365410   \n",
      "43  0.680906 -0.272580 -0.859500  1.238473  0.779405 -0.694311  0.217444   \n",
      "44 -1.654523 -0.272580  0.406697  0.010755 -1.671134  1.299414  1.383152   \n",
      "45  1.070144 -0.272580  0.406697  0.010755  1.129482 -0.694311  0.217444   \n",
      "46  0.914449 -0.272580 -0.859500  1.238473  0.779405  0.302552  0.217444   \n",
      "47  1.070144 -0.272580  1.672893 -1.216964  1.129482 -0.694311 -0.365410   \n",
      "48  1.147992 -0.272580  0.406697  0.010755  1.129482  1.299414 -0.365410   \n",
      "49  0.680906  2.191644  0.406697  0.010755  0.779405 -0.694311 -0.365410   \n",
      "\n",
      "      MGODOV    MGODGE    MRELGE  ...    ALEVEN  APERSONG    AGEZONG  AWAOREG  \\\n",
      "0  -0.068711 -0.161816  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "1  -0.068711  0.464159 -0.096077  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "2   0.914172  0.464159 -1.667319  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "3   0.914172  0.464159 -0.619824  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "4  -0.068711  0.464159  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "5  -1.051594  1.090133 -3.238560  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "6  -1.051594  1.090133  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "7  -1.051594 -0.787790  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "8   1.897055  1.716108 -0.096077  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "9  -1.051594 -0.787790  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "10 -0.068711  0.464159  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "11  0.914172  0.464159  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "12 -0.068711  0.464159 -0.096077  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "13 -1.051594  0.464159  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "14 -0.068711 -0.787790 -2.714813  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "15 -1.051594 -0.787790  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "16 -1.051594 -0.161816  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "17 -1.051594  0.464159  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "18 -1.051594 -0.161816  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "19 -1.051594  2.342082  1.475164  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "20 -1.051594 -0.161816  1.475164  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "21  0.914172 -0.161816  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "22 -1.051594 -0.787790  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "23 -1.051594 -0.787790  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "24  0.914172  0.464159  0.951417  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "25 -0.068711 -0.787790 -0.096077  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "26 -1.051594  0.464159  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "27 -1.051594  1.716108  1.475164  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "28 -1.051594 -2.039739 -0.619824  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "29 -0.068711 -0.787790 -0.619824  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "30  0.914172  0.464159 -2.191066  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "31  0.914172  0.464159  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "32 -0.068711  1.090133  0.951417  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "33  0.914172 -0.787790 -1.143571  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "34  0.914172  0.464159  0.951417  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "35 -0.068711  0.464159 -0.096077  ...  2.445838 -0.073165  12.337363 -0.05992   \n",
      "36  0.914172 -2.039739  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "37 -0.068711 -0.787790  0.951417  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "38 -1.051594 -0.161816 -0.096077  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "39  1.897055  1.090133 -0.096077  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "40 -0.068711 -0.161816 -0.096077  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "41 -1.051594 -2.039739  1.475164  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "42 -0.068711  0.464159 -0.096077  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "43 -1.051594  0.464159  0.951417  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "44 -1.051594 -2.039739  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "45 -0.068711 -0.161816  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "46 -0.068711 -0.161816 -0.096077  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "47 -1.051594  1.090133  0.951417  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "48 -0.068711 -0.161816  0.951417  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "49 -1.051594  1.090133  0.427670  ... -0.202910 -0.073165  -0.081055 -0.05992   \n",
      "\n",
      "      ABRAND   AZEILPL  APLEZIER    AFIETS    AINBOED  ABYSTAND  \n",
      "0   0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "1   0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "2   0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "3   0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "4   0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "5  -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "6  -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "7  -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "8  -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "9   0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "10 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "11  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "12 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "13 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "14  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "15  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "16 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "17  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "18  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "19 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "20 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "21  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "22  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "23 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "24 -1.014358 -0.022706  -0.07365  4.589446  -0.087348 -0.118816  \n",
      "25  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "26 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "27  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "28 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "29  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "30  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "31 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "32  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "33 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "34  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "35  0.764971 -0.022706  -0.07365 -0.150620  -0.087348  8.215515  \n",
      "36  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "37  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "38  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "39  0.764971 -0.022706  -0.07365 -0.150620  10.967836 -0.118816  \n",
      "40  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "41  2.544299 -0.022706  -0.07365  4.589446  -0.087348 -0.118816  \n",
      "42  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "43 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "44  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "45  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "46  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "47  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "48 -1.014358 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "49  0.764971 -0.022706  -0.07365 -0.150620  -0.087348 -0.118816  \n",
      "\n",
      "[50 rows x 85 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select predictors (excluding the 86th column)\n",
    "predictors = Caravan.iloc[:, :-1]\n",
    "\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "predictors_standardized = pd.DataFrame(scaler.fit_transform(predictors), columns=predictors.columns)\n",
    "\n",
    "# Display the head of the standardized predictors\n",
    "print(predictors_standardized.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(v)_ Why is it important to standardize the predictor variables?  \n",
    "Each predictor has its own scale. While one predictor could have a very large number, others could be very small. The difference in scaling can lead to errors and increase them. So, the goal is to normalize every predictor to the same scale between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(vi)_ Why did we elect not to standard our response variable `Purchase`? </br>\n",
    "Our response variable 'Purchase' can only have values of 0 or 1. So, it can be considered as already normalized.\n",
    "Normalization of response could complicate the interpetation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_(vii)_ A second essential step is to set a random seed. Do so below (Hint: use the `random.seed` function). Why is setting a seed important? Is the particular seed value important? Why or why not?</br>\n",
    "Using the function random.seed ensures that we will obtain the same results from random operations when we use it with the same particular value. It's important to use the same value, not just any number. This feature is crucial for comparing, testing, and debugging results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here\n",
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(viii)_ A third essential step is to split our standardized data into separate training and testing sets. We will split into 75% training and 25% testing. The provided code randomly partitions our data, and creates linked training sets for the predictors and response variables. Extend the code to create a non-overlapping test set for the predictors and response variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random vector of True and False values\n",
    "split = np.random.choice([True, False], size=len(predictors_standardized), replace=True, p=[0.75, 0.25])\n",
    "\n",
    "# Define the training set for X (predictors)\n",
    "training_X = predictors_standardized[split]\n",
    "\n",
    "# Define the training set for Y (response)\n",
    "training_Y = Caravan.loc[split, 'Purchase']\n",
    "\n",
    "# Define the testing set for X (predictors)\n",
    "testing_X = predictors_standardized[~split]\n",
    "\n",
    "# Define the testing set for Y (response)\n",
    "testing_Y = Caravan.loc[~split, 'Purchase']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(ix)_ We are finally set to fit the KNN model. In Python, we can use the `KNeighborsClassifier()` function. Fit the KNN with k=1. (You may review arguments to knn by typing `help(knn.fit)`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>1329</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>96</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth        No  Yes\n",
       "Predicted           \n",
       "No         1329   67\n",
       "Yes          96   14"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code here\n",
    "knn = KNeighborsClassifier( n_neighbors=1 )\n",
    "knn.fit( training_X, training_Y )\n",
    "knn_pred = knn.predict( testing_X )\n",
    "confusion_table( knn_pred, testing_Y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your fit model, answer the following questions:   \n",
    "_(x)_ What is the prediction accuracy? (Hint: use the `score` method, and compare your model to `testing_Y`)</br> Accuracy rate is almost 89% which is very good.\n",
    "\n",
    "\n",
    "_(xi)_ What is the predictor error ? (Hint: compute it from the accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8917662682602921, 0.8917662682602921)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction accuracy rate\n",
    "acc_np = np.mean(knn_pred == testing_Y)\n",
    "acc_score = knn.score(testing_X, testing_Y)\n",
    "acc_np, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10823373173970785"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction error rate\n",
    "pred_err_rate = 1 - acc_score\n",
    "pred_err_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(xii)_ How does this prediction error/accuracy compare to what could be achieved via random guesses? To answer this, consider the percent of customers in the `Caravan` dataset who actually purchase insurance, computed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.977327378907591\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of customers who purchase insurance\n",
    "percentage_purchase = (Caravan['Purchase'].eq('Yes').sum() / len(Caravan['Purchase'])) * 100\n",
    "\n",
    "print(percentage_purchase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains only 6% of \"YES\" cases, so guessing a \"Yes\" case correctly is very difficult. </br>\n",
    "Our model has an accuracy of 17% ( 14 / ( 67+14 ) * 100 )for predicting \"Yes\" cases.\n",
    "\n",
    "If we consider guessing \"YES/NO\" as a 50% probability for each. 6% \"Yes\" cases. Than general accuracy for both (YES\\No) cases would be 56%  compared to the model's prediction accuracy of 89%.\n",
    "\n",
    "The model's accuracy is significantly higher, even before finding the best value of K. Therefore, our model is much more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(xiii)_ Fit a second KNN model, with $K=3$. Does this model perform better (i.e., have higher accuracy, compared to a random guess)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9329349269588313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>1400</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth        No  Yes\n",
       "Predicted           \n",
       "No         1400   76\n",
       "Yes          25    5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "knn3 = KNeighborsClassifier( n_neighbors=3 )\n",
    "knn3.fit( training_X, training_Y )\n",
    "knn_pred = knn3.predict( testing_X )\n",
    "\n",
    "acc_np = np.mean(knn_pred == testing_Y)\n",
    "print ( acc_np )\n",
    "confusion_table( knn_pred, testing_Y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $K=3$ increases accuracy by 4%, which is better than the same model with $K=1$ and significantly greater than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criteria\n",
    "\n",
    "|Criteria            |Complete           |Incomplete          |\n",
    "|--------------------|---------------|--------------|\n",
    "|Classification using KNN|All steps are done correctly and the answers are correct.|At least one step is done incorrectly leading to a wrong answer.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-2`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_2.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/applied_statistical_concepts/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
